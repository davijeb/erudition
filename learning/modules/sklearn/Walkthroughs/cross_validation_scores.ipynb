{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test. Note that the word “experiment” is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally. Here is a flowchart of typical cross validation workflow in model training. The best parameters can be determined by grid search techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import (TimeSeriesSplit, KFold, ShuffleSplit,\n",
    "                                     StratifiedKFold, GroupShuffleSplit,\n",
    "                                     GroupKFold, StratifiedShuffleSplit)\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import os, sys, plotly.graph_objects as go\n",
    "module_path = os.path.abspath(os.path.join('../../../../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "from erudition.learning.helpers.plots.plotly_render import render, scatter\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mean = []\n",
    "scores_std = []\n",
    "\n",
    "Cs = np.logspace(-10, 0,10)\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "for c in Cs:\n",
    "    clf1 = svm.SVC(kernel='linear', C=c)\n",
    "    scores  = cross_val_score(clf1, X, y, cv = 5)\n",
    "    scores_mean.append(np.mean(scores))\n",
    "    scores_std.append(np.std(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean = scatter(Cs, scores_mean, 'C Scores Mean', mode='lines')\n",
    "plot_plus_std = scatter(Cs, np.array(scores_mean)+np.array(scores_std), '+std', mode='lines')\n",
    "plot_minus_std = scatter(Cs, np.array(scores_mean)-np.array(scores_std), '-std', mode='lines')\n",
    "fig = go.Figure(data=[plot_mean, plot_plus_std, plot_minus_std])\n",
    "fig.update_layout(xaxis_type=\"log\", yaxis_type=\"log\")\n",
    "render(fig, 'Cross-validation with an SVM on the Digits dataset.', width=900, height=500, x_axis_title='C Parameter', y_axis_title='CV Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination with Cross Validation\n",
    "\n",
    "Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.\n",
    "\n",
    "Class: REFVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification, load_boston\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "                           n_redundant=2, n_repeated=0, n_classes=8,\n",
    "                           n_clusters_per_class=1, random_state=0)\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "%matplotlib inline\n",
    "\n",
    "p = scatter(np.arange(0, len(rfecv.grid_scores_))+1, rfecv.grid_scores_, '', mode='lines')\n",
    "fig = go.Figure([p])\n",
    "render(fig, \n",
    "       'Recursive Feature Elimination', \n",
    "       x_axis_title='Number of features selected', \n",
    "       y_axis_title='Cross validation score (nb of correct classifications)', \n",
    "       showlegend=False,\n",
    "       width=1000,\n",
    "       height=500\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
