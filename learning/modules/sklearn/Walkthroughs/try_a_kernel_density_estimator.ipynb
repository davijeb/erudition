{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernels\n",
    "Kernel density estimates are closely related to histograms, but can be endowed with properties such as smoothness or continuity by using a suitable kernel.\n",
    "\n",
    "# Parametric vs Non Parametric\n",
    "A large portion of the field of statistics and statistical methods is dedicated to data where the distribution is known.\n",
    "\n",
    "Samples of data where we already know or can easily identify the distribution of are called parametric data. Often, parametric is used to refer to data that was drawn from a Gaussian distribution in common usage. Data in which the distribution is unknown or cannot be easily identified is called nonparametric.\n",
    "\n",
    "In the case where you are working with nonparametric data, specialized nonparametric statistical methods can be used that discard all information about the distribution. As such, these methods are often referred to as distribution-free methods.\n",
    "\n",
    "## Parametric Data\n",
    "\n",
    "Parametric data is a sample of data drawn from a known data distribution.\n",
    "\n",
    "This means that we already know the distribution or we have identified the distribution, and that we know the parameters of the distribution. Often, parametric is shorthand for real-valued data drawn from a Gaussian distribution. This is a useful shorthand, but strictly this is not entirely accurate.\n",
    "\n",
    "If we have parametric data, we can use parametric methods. Continuing with the shorthand of parametric meaning Gaussian. If we have parametric data, we can harness the entire suite of statistical methods developed for data assuming a Gaussian distribution, such as:\n",
    "\n",
    "- Summary statistics.\n",
    "- Correlation between variables.\n",
    "- Significance tests for comparing means.\n",
    "\n",
    "In general, we prefer to work with parametric data, and even go so far as to use data preparation methods that make data parametric, such as data transforms, so that we can harness these well-understood statistical methods.Nonparametric Data\n",
    "Data that does not fit a known or well-understood distribution is referred to as nonparametric data.\n",
    "\n",
    "## Non Parametric Data\n",
    "\n",
    "Data could be non-parametric for many reasons, such as:\n",
    "\n",
    "- Data is not real-valued, but instead is ordinal, intervals, or some other form.\n",
    "- Data is real-valued but does not fit a well understood shape.\n",
    "- Data is almost parametric but contains outliers, multiple peaks, a shift, or some other feature.\n",
    "\n",
    "There are a suite of methods that we can use for nonparametric data called nonparametric statistical methods. In fact, most parametric methods have an equivalent nonparametric version.\n",
    "\n",
    "In general, the findings from nonparametric methods are less powerful than their parametric counterparts, namely because they must be generalized to work for all types of data. We can still use them for inference and make claims about findings and results, but they will not hold the same weight as similar claims with parametric methods. Information about the distribution is discarded.\n",
    "\n",
    "In the case of ordinal or interval data, nonparametric statistics are the only type of statistics that can be used. For real-valued data, nonparametric statistical methods are required in applied machine learning when you are trying to make claims on data that does not fit the familiar Gaussian distribution.\n",
    "\n",
    "Nonparametric Data\n",
    "\n",
    "Data that does not fit a known or well-understood distribution is referred to as nonparametric data.\n",
    "Data could be non-parametric for many reasons, such as:\n",
    "\n",
    "- Data is not real-valued, but instead is ordinal, intervals, or some other form.\n",
    "- Data is real-valued but does not fit a well understood shape.\n",
    "- Data is almost parametric but contains outliers, multiple peaks, a shift, or some other feature.\n",
    "\n",
    "There are a suite of methods that we can use for nonparametric data called nonparametric statistical methods. In fact, most parametric methods have an equivalent nonparametric version.\n",
    "\n",
    "In general, the findings from nonparametric methods are less powerful than their parametric counterparts, namely because they must be generalized to work for all types of data. We can still use them for inference and make claims about findings and results, but they will not hold the same weight as similar claims with parametric methods. Information about the distribution is discarded.\n",
    "\n",
    "In the case of ordinal or interval data, nonparametric statistics are the only type of statistics that can be used. For real-valued data, nonparametric statistical methods are required in applied machine learning when you are trying to make claims on data that does not fit the familiar Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from distutils.version import LooseVersion\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import os, sys, plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "module_path = os.path.abspath(os.path.join('../../../../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets \n",
    "from erudition.learning.modules.sklearn.GeneralizedLinearModels.helper import helper\n",
    "from erudition.learning.helpers.plots.plotly_render import render, scatter\n",
    "\n",
    "# `normed` is being deprecated in favor of `density` in histograms\n",
    "if LooseVersion(matplotlib.__version__) >= '2.1':\n",
    "    density_param = {'density': True}\n",
    "else:\n",
    "    density_param = {'normed': True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To see this, we compare the construction of histogram and kernel density estimators, using these 6 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [-2.1, -1.3, -0.4, 1.9, 5.1, 6.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "x = data\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x, opacity=0.5,  name='Points', xbins=dict(\n",
    "                      start=-20,\n",
    "                      end=10,\n",
    "                      size= 2), autobinx = False)])\n",
    "render(fig, title='Basic Histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the bandwidth changes the shape of the kernel: a lower bandwidth means only points very \n",
    "# close to the current position are given any weight, which leads to the estimate \n",
    "# looking squiggly; a higher bandwidth means a shallow kernel where distant points can contribute.\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=1.5).fit(np.array(data)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(-10, 10, 1000)[:, np.newaxis]\n",
    "log_dens = kde.score_samples(X_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(scatter(X_plot[:,0], np.exp(log_dens), 'Points'))\n",
    "render(fig, 'Gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
