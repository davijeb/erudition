{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Data Analysis\n",
    "\n",
    "Before tackling any problem with complex mathematics it is vital to understand the data. \n",
    "\n",
    "- Understand the problem. We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n",
    "- Univariable study. We'll just focus on the dependent variable ('SalePrice') and try to know a little bit more about it.\n",
    "- Multivariate study. We'll try to understand how the dependent variable and independent variables relate.\n",
    "- Basic cleaning. We'll clean the dataset and handle the missing data, outliers and categorical variables.\n",
    "- Test assumptions. We'll check if our data meets the assumptions required by most multivariate techniques.\n",
    "\n",
    "Let's move away from using Plotly to Seaborn as it has some really useful utlities to get us started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '~/notebooks/erudition/data/kaggle/house-prices-advanced-regression-techniques'\n",
    "\n",
    "# bring in the data\n",
    "df =pd.read_csv(DIR + os.sep + 'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the decoration\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ultimately care about the SalePrice so lets carry out some initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There looks to be a large range between the lowest and highest priced houses.\n",
    "Let's plot a histogram to visualise this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance we can clearly see it:\n",
    "\n",
    "- Deviates from the normal distribution.\n",
    "- Has appreciable positive skewness.\n",
    "- Shows peakedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets dig further into the shape of the curve\n",
    "\n",
    "print('Skewness: ', df.SalePrice.skew(), ' Kurtosis: ', df.SalePrice.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=df.plot.scatter(x='GrLivArea', y='SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a nice linear relationship between these two **independent variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=df.plot.scatter(x='TotalBsmtSF', y='SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There now appears to be some features around TotalBsmtSF=0 and a more exponential relationship. The larger the TotalBsmtSF value the more increase we see in the SalePrice value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the relationships to more caregoricl features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "p=sns.boxplot(x='OverallQual', y=\"SalePrice\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an obvious relationship between the overall quality andthe sales price. Better quality = higher sale price.\n",
    "\n",
    "What about the year the property was built?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "p=sns.boxplot(x='YearBuilt', y=\"SalePrice\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plasma Soup\n",
    "\n",
    "We know more about the data now and have some obvious trends as surfaced above but how do all the features relate to one another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmap = df.corr()\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "p=sns.heatmap(corrmap, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of data although there are some obvious features which are highly correlated. Let's explore the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmap = df.corr()\n",
    "cols = corrmap.nlargest(10, 'SalePrice')['SalePrice'].index\n",
    "corrmap = df[cols].corr()\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "p=sns.heatmap(corrmap, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information we can now look at the actual scatter plot relationships between the features using Seaborns pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=sns.pairplot(df[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mising Data\n",
    "\n",
    "Is there anything missing in our data? This can have a huge effect on any training model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.isna().sum().sort_values(ascending=False)\n",
    "percentage = (df.isna().sum()/df.isna().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percentage], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with missing data\n",
    "df= df.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
    "df = df.drop(df.loc[df['Electrical'].isnull()].index)\n",
    "df.isnull().sum().max() #just checking that there's no missing data missing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out liars\n",
    "\n",
    "Outliers can markedly affect our models and can be a valuable source of information, providing us insights about specific behaviours.\n",
    "\n",
    "Quick analysis through the standard deviation of 'SalePrice' and a set of scatter plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four assumptions should be tested\n",
    "\n",
    "According to Hair et al. (2013)\n",
    "\n",
    "https://is.muni.cz/el/1423/podzim2017/PSY028/um/_Hair_-_Multivariate_data_analysis_7th_revised.pdf\n",
    "\n",
    "- **Normality** - When we talk about normality what we mean is that the data should look like a normal distribution. This is important because several statistic tests rely on this (e.g. t-statistics). In this exercise we'll just check univariate normality for 'SalePrice' (which is a limited approach). Remember that univariate normality doesn't ensure multivariate normality (which is what we would like to have), but it helps. Another detail to take into account is that in big samples (>200 observations) normality is not such an issue. However, if we solve normality, we avoid a lot of other problems (e.g. heteroscedacity) so that's the main reason why we are doing this analysis.\n",
    "\n",
    "- **Homoscedasticity** - I just hope I wrote it right. Homoscedasticity refers to the 'assumption that dependent variable(s) exhibit equal levels of variance across the range of predictor variable(s)' (Hair et al., 2013). Homoscedasticity is desirable because we want the error term to be the same across all values of the independent variables.\n",
    "\n",
    "- **Linearity** - The most common way to assess linearity is to examine scatter plots and search for linear patterns. If patterns are not linear, it would be worthwhile to explore data transformations. However, we'll not get into this because most of the scatter plots we've seen appear to have linear relationships.\n",
    "\n",
    "- **Absence of correlated errors** - Correlated errors, like the definition suggests, happen when one error is correlated to another. For instance, if one positive error makes a negative error systematically, it means that there's a relationship between these variables. This occurs often in time series, where some patterns are time related. We'll also not get into this. However, if you detect something, try to add a variable that can explain the effect you're getting. That's the most common solution for correlated errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with a search for Normality\n",
    "\n",
    "- **Histogram** - Kurtosis and skewness.\n",
    "- **Normal probability plot** - Data distribution should closely follow the diagonal that represents the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "from scipy import stats\n",
    "sns.distplot(df['SalePrice'], fit=norm);\n",
    "fig = plt.figure()\n",
    "\n",
    "# Calculate quantiles for a probability plot, and optionally show the plot.\n",
    "# Generates a probability plot of sample data against the quantiles of a specified theoretical distribution (the normal distribution by default). \n",
    "# probplot optionally calculates a best-fit line for the data and plots the results using Matplotlib or a given plot function.\n",
    "res = stats.probplot(df['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm, the SalePrice does not appear normal. It shows peakedness, positive skewness and does not follow the diagonal line that would indicate a purely normaly distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSITIVE SKEWNESS & LOG TRANSFORM\n",
    "\n",
    "But everything's not lost. A simple data transformation can solve the problem. This is one of the awesome things you can learn in statistical books: in case of positive skewness, log transformations usually works well. When I discovered this, I felt like an Hogwarts' student discovering a new cool spell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice = np.log(df.SalePrice)\n",
    "\n",
    "sns.distplot(df['SalePrice'], fit=norm);\n",
    "fig = plt.figure()\n",
    "\n",
    "# Calculate quantiles for a probability plot, and optionally show the plot.\n",
    "# Generates a probability plot of sample data against the quantiles of a specified theoretical distribution (the normal distribution by default). \n",
    "# probplot optionally calculates a best-fit line for the data and plots the results using Matplotlib or a given plot function.\n",
    "res = stats.probplot(df['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "\n",
    "# Calculate quantiles for a probability plot, and optionally show the plot.\n",
    "# Generates a probability plot of sample data against the quantiles of a specified theoretical distribution (the normal distribution by default). \n",
    "# probplot optionally calculates a best-fit line for the data and plots the results using Matplotlib or a given plot function.\n",
    "res = stats.probplot(df['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a similar issue as before, let transform and re-draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GrLivArea = np.log(df.GrLivArea)\n",
    "\n",
    "sns.distplot(df['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "\n",
    "# Calculate quantiles for a probability plot, and optionally show the plot.\n",
    "# Generates a probability plot of sample data against the quantiles of a specified theoretical distribution (the normal distribution by default). \n",
    "# probplot optionally calculates a best-fit line for the data and plots the results using Matplotlib or a given plot function.\n",
    "res = stats.probplot(df['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['TotalBsmtSF'], fit=norm);\n",
    "fig = plt.figure()\n",
    "\n",
    "# Calculate quantiles for a probability plot, and optionally show the plot.\n",
    "# Generates a probability plot of sample data against the quantiles of a specified theoretical distribution (the normal distribution by default). \n",
    "# probplot optionally calculates a best-fit line for the data and plots the results using Matplotlib or a given plot function.\n",
    "res = stats.probplot(df['TotalBsmtSF'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
